# Backend - Rabensteiner Engineering

Backend application for Rabensteiner Engineering data processing and ML model training system.

## ğŸ“‹ Overview

The backend provides:
- Chunked CSV data upload and processing
- Time series processing and transformation
- Training of various ML models (Dense, CNN, LSTM, SVR, Linear)
- Real-time progress tracking via WebSocket
- Cloud integration with Supabase
- Automatic cleanup of old files

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- pip
- Virtual environment (recommended)

### Installation Steps

1. **Clone the repository**
```bash
git clone https://github.com/your-repo/Backend_RabensteinerEng.git
cd Backend_RabensteinerEng/my_backend
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env file with your settings
```

## ğŸ—ï¸ Architecture

```
my_backend/
â”œâ”€â”€ api/routes/           # API endpoints (Flask blueprints)
â”‚   â”œâ”€â”€ adjustments.py    # Data adjustments endpoints
â”‚   â”œâ”€â”€ cloud.py          # Cloud operations
â”‚   â”œâ”€â”€ data_processing.py# Main data processing
â”‚   â”œâ”€â”€ first_processing.py# Initial processing
â”‚   â”œâ”€â”€ load_data.py      # Data upload endpoints
â”‚   â””â”€â”€ training.py       # ML training endpoints
â”œâ”€â”€ services/             # Business logic
â”‚   â”œâ”€â”€ adjustments/      # Data adjustment services
â”‚   â”œâ”€â”€ cloud/            # Cloud integration
â”‚   â”œâ”€â”€ data_processing/  # Processing logic
â”‚   â”œâ”€â”€ training/         # ML training pipeline
â”‚   â””â”€â”€ upload/           # File upload handlers
â”œâ”€â”€ core/                 # Application core
â”‚   â”œâ”€â”€ app_factory.py    # Flask app creation
â”‚   â”œâ”€â”€ extensions.py     # Flask extensions
â”‚   â””â”€â”€ socketio_handlers.py # WebSocket handlers
â”œâ”€â”€ utils/                # Utilities
â”‚   â””â”€â”€ database.py       # Supabase client
â”œâ”€â”€ models/               # Data models
â”œâ”€â”€ config/               # Configuration
â”œâ”€â”€ storage/              # File storage
â””â”€â”€ app.py               # Entry point
```

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# Flask
FLASK_ENV=development
PORT=8080

# Supabase
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key

# Upload settings
MAX_CONTENT_LENGTH=104857600  # 100MB
UPLOAD_FOLDER=uploads
TEMP_FOLDER=temp_uploads
```

## ğŸš¦ Running the Application

### Development Mode
```bash
python app.py
```

Server will be available at `http://localhost:8080`

### Production Mode
```bash
gunicorn -w 4 -b 0.0.0.0:8080 --timeout 300 app:app
```

### Docker
```bash
docker build -t rabensteiner-backend .
docker run -p 8080:8080 --env-file .env rabensteiner-backend
```

## ğŸ“¡ API Endpoints

### Health Check
- `GET /` - Server status
- `GET /health` - Health check

### Data Upload
- `POST /api/loadRowData/upload-chunk` - Upload data in chunks
- `POST /api/loadRowData/finalize-upload` - Finalize upload
- `POST /api/loadRowData/cancel-upload` - Cancel upload

### Data Processing
- `POST /api/firstProcessing/upload_chunk` - Initial processing
- `POST /api/dataProcessingMain/upload-chunk` - Main processing
- `POST /api/adjustmentsOfData/process` - Data adjustments

### Training
- `POST /api/training/generate-dataset` - Generate dataset
- `POST /api/training/train` - Train models
- `GET /api/training/status/<session_id>` - Training status

### Cloud Operations
- `POST /api/cloud/upload-chunk` - Cloud upload
- `POST /api/cloud/clouddata` - Retrieve cloud data
- `POST /api/cloud/interpolate-chunked` - Data interpolation

## ğŸ”Œ WebSocket Events

### Client â†’ Server
- `connect` - Connect to server
- `join` - Join room
- `join_training_session` - Join training session
- `request_training_status` - Request training status

### Server â†’ Client
- `upload_progress` - Upload progress
- `training_status_update` - Training status update
- `dataset_status_update` - Dataset generation status
- `processing_error` - Processing error

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/

# With coverage
python -m pytest --cov=. tests/
```

## ğŸ“¦ Deployment

### Google Cloud Run
```bash
gcloud builds submit --tag gcr.io/PROJECT_ID/rabensteiner-backend
gcloud run deploy --image gcr.io/PROJECT_ID/rabensteiner-backend --platform managed
```

### Render.com
1. Connect GitHub repository
2. Set environment variables
3. Auto-deploy on push

## ğŸ› Debugging

### Logging
```python
import logging
logger = logging.getLogger(__name__)
logger.debug("Debug message")
logger.info("Info message")
logger.error("Error message")
```

### Common Issues

**Port already in use:**
```bash
lsof -i :8080
kill -9 <PID>
```

**Import errors:**
Check that you're in the correct directory and virtual environment is activated.

**Supabase connection:**
Verify that SUPABASE_URL and SUPABASE_KEY are correctly set in .env file.

## ğŸ“„ License

Proprietary - Rabensteiner Engineering

## ğŸ‘¥ Team

- Backend Development Team
- ML Engineering Team

## ğŸ“ Contact

For questions and support, contact the development team.

---

**Version:** 1.0.0  
**Last Updated:** August 2024