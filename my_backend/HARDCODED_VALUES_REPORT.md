# üìä IZVE≈†TAJ O HARDKODOVANIM VREDNOSTIMA U TRAINING SISTEMU

**Datum analize**: 2025-01-31  
**Analizirani sistem**: Frontend (React/TypeScript) + Backend (Flask/Python)

---

## üîç REZIME

Pronaƒëeno je **15+ hardkodovanih vrednosti** koje bi trebalo da budu konfigurabine od strane korisnika. Najkritiƒçnije su one vezane za training proces koje direktno utiƒçu na performanse modela.

---

## üìã LISTA HARDKODOVANIH VREDNOSTI

### üé® FRONTEND (Training.tsx)

#### ‚úÖ Vrednosti koje korisnik MO≈ΩE da menja:
1. **Model parametri** (preko ModelConfiguration komponente):
   - MODE (tip modela)
   - LAY (broj slojeva)
   - N (broj neurona/filtera)
   - EP (broj epoha)
   - ACTF (aktivaciona funkcija)
   - K (kernel size za CNN)
   - KERNEL (tip kernela za SVR)
   - C i EPSILON (SVR parametri)

2. **Training data split** (preko TrainingDataSplit komponente):
   - trainPercentage
   - valPercentage  
   - testPercentage
   - random_dat (randomizacija)

#### ‚ùå Vrednosti koje korisnik NE MO≈ΩE da menja:
```typescript
const POLLING_CONFIG = {
    DATASET_GENERATION_INTERVAL: 5000,      // ‚ö†Ô∏è HARDKODOVANO
    MODEL_TRAINING_INTERVAL: 10000,         // ‚ö†Ô∏è HARDKODOVANO
    ANALYSIS_STATUS_INTERVAL: 10000,        // ‚ö†Ô∏è HARDKODOVANO
    MAX_POLLING_ATTEMPTS: 100,              // ‚ö†Ô∏è HARDKODOVANO
    TIMEOUT_MINUTES: 5                      // ‚ö†Ô∏è HARDKODOVANO
};
```

### üîß BACKEND (parameter_converter.py i config.py)

#### ‚ùå KRITIƒåNE hardkodovane vrednosti koje korisnik NE MO≈ΩE da menja:

##### 1. **Training parametri za sve Neural Network modele**:
```python
VAL_S: float = 0.2          # ‚ö†Ô∏è Validation split - UVEK 20%
BS: int = 32                # ‚ö†Ô∏è Batch size - UVEK 32
LR: float = 0.001           # ‚ö†Ô∏è Learning rate - UVEK 0.001
OPT: str = "adam"           # ‚ö†Ô∏è Optimizer - UVEK Adam
LOSS: str = "mse"           # ‚ö†Ô∏è Loss function - UVEK MSE
METRICS: List[str] = ["mae"] # ‚ö†Ô∏è Metrics - UVEK samo MAE
```

##### 2. **CNN specifiƒçne hardkodovane vrednosti**:
```python
L1_P: int = 2               # ‚ö†Ô∏è Pool size za prvi sloj
L2_P: int = 2               # ‚ö†Ô∏è Pool size za drugi sloj
L3_N: int = 50              # ‚ö†Ô∏è Dense layer neurons - FIKSNO 50
```

##### 3. **LSTM specifiƒçne hardkodovane vrednosti**:
```python
L1_D: float = 0.2           # ‚ö†Ô∏è Dropout za prvi LSTM sloj
L2_D: float = 0.2           # ‚ö†Ô∏è Dropout za drugi LSTM sloj
L1_RS: bool = True          # ‚ö†Ô∏è Return sequences za prvi sloj
L2_RS: bool = False         # ‚ö†Ô∏è Return sequences za drugi sloj
L3_N: int = 25              # ‚ö†Ô∏è Dense layer neurons - FIKSNO 25
```

##### 4. **SVR specifiƒçne hardkodovane vrednosti**:
```python
GAMMA: str = "scale"        # ‚ö†Ô∏è Kernel coefficient
DEGREE: int = 3             # ‚ö†Ô∏è Polynomial degree
COEF0: float = 0.0          # ‚ö†Ô∏è Independent term
SHRINKING: bool = True      # ‚ö†Ô∏è Shrinking heuristic
TOL: float = 0.001          # ‚ö†Ô∏è Tolerance
CACHE_SIZE: int = 200       # ‚ö†Ô∏è Cache size in MB
MAX_ITER: int = -1          # ‚ö†Ô∏è Maximum iterations
```

---

## üö® KRITIƒåNA ANALIZA

### Najva≈ænije problemi:

1. **Validation Split (VAL_S = 0.2)**
   - Trenutno: UVEK 20% podataka za validaciju
   - Problem: Korisnik ne mo≈æe da prilagodi ovaj odnos svojim potrebama
   - Uticaj: Za male datasets, 20% mo≈æe biti previ≈°e za validaciju

2. **Batch Size (BS = 32)**
   - Trenutno: FIKSNO 32 za sve modele
   - Problem: Razliƒçiti modeli i datasets zahtevaju razliƒçite batch sizes
   - Uticaj: Mo≈æe negativno uticati na konvergenciju i brzinu treniranja

3. **Learning Rate (LR = 0.001)**
   - Trenutno: FIKSNO 0.001 za sve modele
   - Problem: Kritiƒçan hiperparametar koji zavisi od problema
   - Uticaj: Mo≈æe dovesti do lo≈°eg treniranja ili divergencije

4. **Optimizer (OPT = "adam")**
   - Trenutno: Samo Adam optimizer
   - Problem: Razliƒçiti problemi mogu zahtevati razliƒçite optimizatore
   - Uticaj: Ograniƒçava fleksibilnost treniranja

---

## üí° PREPORUKE ZA IZMENE

### üî¥ PRIORITET 1 (Kritiƒçno):

1. **Dodati u ModelConfiguration.tsx**:
   ```typescript
   // Za sve modele
   batchSize: number
   learningRate: number  
   optimizer: 'adam' | 'sgd' | 'rmsprop' | 'adagrad'
   validationSplit: number (0.1 - 0.4)
   ```

2. **Dodati za CNN**:
   ```typescript
   poolSizes: number[]  // Za svaki conv layer
   denseLayers: number[] // Konfigurabini dense slojevi
   ```

3. **Dodati za LSTM**:
   ```typescript
   dropoutRates: number[] // Za svaki LSTM layer
   returnSequences: boolean[] // Za svaki LSTM layer
   ```

### üü° PRIORITET 2 (Va≈æno):

1. **Loss function izbor**:
   ```typescript
   lossFunction: 'mse' | 'mae' | 'huber' | 'binary_crossentropy'
   ```

2. **Metrics izbor**:
   ```typescript
   metrics: string[] // ['mae', 'mse', 'rmse', 'mape']
   ```

3. **Early Stopping parametri**:
   ```typescript
   earlyStoppingPatience: number
   earlyStoppingMinDelta: number
   ```

### üü¢ PRIORITET 3 (Nice to have):

1. **Polling konfiguracija**:
   - Omoguƒáiti korisniku da podesi polling intervale
   - Ili bar prikazati progress bar sa procenom vremena

2. **SVR napredni parametri**:
   - gamma, degree, coef0 za razliƒçite kernel tipove
   - tolerance i max iterations

---

## üìù IMPLEMENTACIONE BELE≈†KE

### Frontend izmene potrebne u:
1. `ModelConfiguration.tsx` - Dodati nova input polja
2. `TrainingApiService.ts` - Proslediti nove parametre
3. `modelParameterUtils.ts` - Validacija novih parametara

### Backend izmene potrebne u:
1. `parameter_converter.py` - Prihvatiti nove parametre sa frontenda
2. `model_trainer.py` - Koristiti prosleƒëene parametre umesto default vrednosti

---

## üéØ ZAKLJUƒåAK

Trenutni sistem ima znaƒçajan broj hardkodovanih vrednosti koje ograniƒçavaju fleksibilnost treniranja. Najkritiƒçnije su:
- Validation split (20%)
- Batch size (32)
- Learning rate (0.001)
- Optimizer (samo Adam)

Ove vrednosti direktno utiƒçu na kvalitet i brzinu treniranja modela. Preporuƒçuje se prioritetna implementacija konfigurisanja ovih parametara kroz UI.